{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Stemming strips a word to it's root form.  E.g the words \"eat\", \"eating\", \"eaten\" all have \"eat\" as the stem.\n",
    "We use stemming whereever we want to group words that have the same root.  Often, when performing machine processing of text, we use stemming so that the information value of the text is increased.  This can improve the performance of any algorithms that rely on this information value, such as machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming Algorithms\n",
    "These algorithms work though suffix-stripping.  It's a pretty mechanical task, applying some very simple rules.  Porter stemmer is the most simple, with rules such as:\n",
    "- if the word ends in 'ed', remove the 'ed'\n",
    "- if the word ends in 'ing', remove the 'ing'\n",
    "- if the word ends in 'ly', remove the 'ly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 well-know stemming algorithms.  \n",
    "Porter Stemmer is a very gentle algorithm, in that it doesn't aggressively remove suuffixes.\n",
    "Snowball Stemmer, which addresses some issues in the Porter Stemmer and is slightly more aggressive.\n",
    "Lancaster Stemmer, which is quite agressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dance = [\"dance\", \"danced\", \"dancing\", \"dancer\", \"dances\"]\n",
    "fish = [\"fishing\",\"fisher\",\"fished\",\"fishes\"]\n",
    "sport = [\"sport\", \"sporty\", \"sporting\", \"sportingly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porterStemList(x):\n",
    "    ps = PorterStemmer()\n",
    "    for w in x:\n",
    "        rootWord = ps.stem(w)\n",
    "        print(w, \"->\", rootWord)\n",
    "        \n",
    "def snowballStemList(x):\n",
    "    ss = SnowballStemmer(language=\"english\")\n",
    "    for w in x:\n",
    "        rootWord = ss.stem(w)\n",
    "        print(w, \"->\", rootWord)\n",
    "                \n",
    "def lancasterStemList(x):\n",
    "    ls = LancasterStemmer()\n",
    "    for w in x:\n",
    "        rootWord = ls.stem(w)\n",
    "        print(w, \"->\", rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance -> danc\n",
      "danced -> danc\n",
      "dancing -> danc\n",
      "dancer -> dancer\n",
      "dances -> danc\n",
      "fishing -> fish\n",
      "fisher -> fisher\n",
      "fished -> fish\n",
      "fishes -> fish\n",
      "sport -> sport\n",
      "sporty -> sporti\n",
      "sporting -> sport\n",
      "sportingly -> sportingli\n"
     ]
    }
   ],
   "source": [
    "porterStemList(dance) \n",
    "porterStemList(fish) \n",
    "porterStemList(sport) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance -> danc\n",
      "danced -> danc\n",
      "dancing -> danc\n",
      "dancer -> dancer\n",
      "dances -> danc\n",
      "fishing -> fish\n",
      "fisher -> fisher\n",
      "fished -> fish\n",
      "fishes -> fish\n",
      "sport -> sport\n",
      "sporty -> sporti\n",
      "sporting -> sport\n",
      "sportingly -> sport\n"
     ]
    }
   ],
   "source": [
    "snowballStemList(dance) \n",
    "snowballStemList(fish) \n",
    "snowballStemList(sport) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance -> dant\n",
      "danced -> dant\n",
      "dancing -> dant\n",
      "dancer -> dant\n",
      "dances -> dant\n",
      "fishing -> fish\n",
      "fisher -> fish\n",
      "fished -> fish\n",
      "fishes -> fish\n",
      "sport -> sport\n",
      "sporty -> sporty\n",
      "sporting -> sport\n",
      "sportingly -> sport\n"
     ]
    }
   ],
   "source": [
    "lancasterStemList(dance) \n",
    "lancasterStemList(fish) \n",
    "lancasterStemList(sport) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with Stemming\n",
    "In this example, there are a number of different meanings, but the stemmers fail to recognise this.  Stemmers have no concept of how a word is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university -> univers\n",
      "universal -> univers\n",
      "universities -> univers\n",
      "universe -> univers\n",
      "universality -> univers\n"
     ]
    }
   ],
   "source": [
    "uni = [\"university\", \"universal\", \"universities\", \"universe\", \"universality\"]\n",
    "porterStemList(uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "A more complex algorithm than stemming, which uses knowledge of the language to reduce the word to its base dictionary form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in this function we pass in the part of speech (pos) defaulting to noun\n",
    "def lemmatizeList(x, pos=\"n\"):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for w in x:\n",
    "        rootWord = lemmatizer.lemmatize(w, pos=pos)\n",
    "        print(w, \"->\", rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance -> dance\n",
      "danced -> danced\n",
      "dancing -> dancing\n",
      "dancer -> dancer\n",
      "dances -> dance\n",
      "fishing -> fishing\n",
      "fisher -> fisher\n",
      "fished -> fished\n",
      "fishes -> fish\n",
      "university -> university\n",
      "universal -> universal\n",
      "universities -> university\n",
      "universe -> universe\n",
      "universality -> universality\n"
     ]
    }
   ],
   "source": [
    "lemmatizeList(dance) \n",
    "lemmatizeList(fish) \n",
    "lemmatizeList(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip -> strip\n",
      "stripe -> stripe\n",
      "stripes -> stripe\n"
     ]
    }
   ],
   "source": [
    "strip = [\"strip\", \"stripe\", \"stripes\"]\n",
    "\n",
    "lemmatizeList(strip, pos=\"n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip -> strip\n",
      "stripe -> stripe\n",
      "stripes -> strip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemmatizeList(strip, pos=\"v\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming or Lemmatization?\n",
    "Which is better?\n",
    "It depends!  What is your task?  If your task requires preserving meaning of words, lemmatization is probably better.   If your task is more about getting the rough sense of things, then stemming may be better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pwd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2708597cde298b8cf2347d0927b0f1edf1b3719872f30967dc38f4c4a28f502b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
